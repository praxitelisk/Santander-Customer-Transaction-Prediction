{"cells":[{"metadata":{},"cell_type":"markdown","source":"![](https://www.santander.co.uk/themes/custom/santander_web18/logo.svg)\n\n[image-source](https://www.santander.co.uk/themes/custom/santander_web18/logo.svg)\n\n"},{"metadata":{},"cell_type":"markdown","source":"## Main outline"},{"metadata":{},"cell_type":"markdown","source":"<img src=\"data:image/png;base64,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\" style=\"cursor:pointer;max-width:100%;\" onclick=\"(function(img){if(img.wnd!=null&&!img.wnd.closed){img.wnd.focus();}else{var r=function(evt){if(evt.data=='ready'&&evt.source==img.wnd){img.wnd.postMessage(decodeURIComponent(img.getAttribute('src')),'*');window.removeEventListener('message',r);}};window.addEventListener('message',r);img.wnd=window.open('https://www.draw.io/?client=1&lightbox=1&edit=_blank');}})(this);\"/>"},{"metadata":{},"cell_type":"markdown","source":"## Exploratory Data Analysis\n\n![](http://blog.k2analytics.co.in/wp-content/uploads/2016/12/Exploratory_Data_Analysis.png)\n\n[image-source](http://blog.k2analytics.co.in/wp-content/uploads/2016/12/Exploratory_Data_Analysis.png)"},{"metadata":{},"cell_type":"markdown","source":"### Importing the dataset"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.style.use('fivethirtyeight')\n\nimport gc\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[{"output_type":"stream","text":"['train.csv', 'sample_submission.csv', 'test.csv']\n","name":"stdout"}]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape, test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"At first glance we have many uncharacterized numerical features, their names has the prefix \"var_\" and they are 200 in numbers. There are so many variables that some histograms will shed light to their numerical appearance."},{"metadata":{"trusted":true},"cell_type":"code","source":"train.target.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['target'].value_counts().plot(kind=\"pie\", figsize=(12,9), colormap=\"coolwarm\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we have a typical imbalanced dataset."},{"metadata":{},"cell_type":"markdown","source":"#### check for missing data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isna().sum().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.isna().sum().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have no NA values which is very nice!!"},{"metadata":{},"cell_type":"markdown","source":"#### Splitting the numerical features"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe()\ngc.collect();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_features = train.columns[2:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Distributions columns')\nplt.figure(figsize=(30, 185))\nfor i, col in enumerate(numerical_features):\n    plt.subplot(50, 4, i + 1)\n    plt.hist(train[col]) \n    plt.title(col)\ngc.collect();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Almost all features shows a normal distribution shape. Lets see the distributions for for all numerical features per each class."},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Distributions columns')\nplt.figure(figsize=(30, 185))\nfor i, col in enumerate(numerical_features):\n    plt.subplot(50, 4, i + 1)\n    plt.hist(train[train[\"target\"] == 0][col], alpha=0.5, label='0', color='b')\n    plt.hist(train[train[\"target\"] == 1][col], alpha=0.5, label='1', color='r')    \n    plt.title(col)\ngc.collect();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20, 8))\ntrain[numerical_features].mean().plot('hist');\nplt.title('Mean Frequency');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20, 8))\ntrain[numerical_features].median().plot('hist');\nplt.title('Median Frequency');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20, 8))\ntrain[numerical_features].std().plot('hist');\nplt.title('Standard Deviation Frequency');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Most of the distributions show small std. deviations, and very few more than 20. Maybe a log transformation or a scaling technique to all features will alter the graph above to a normal one. "},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20, 8))\ntrain[numerical_features].skew().plot('hist');\nplt.title('Skewness Frequency');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20, 8))\ntrain[numerical_features].kurt().plot('hist');\nplt.title('Kurtosis Frequency');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Both Skewness and Kurtosis show that the features distributions are like a normal one."},{"metadata":{},"cell_type":"markdown","source":"#### correlations between numerical data"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(rc={'figure.figsize':(20,28)})\n\n# Compute the correlation matrix\ncorr = train[numerical_features].corr()\n\n# Generate a mask for the upper triangle\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\nsns.heatmap(corr, mask=mask, \n            #annot=True, \n            #fmt=\".2f\", \n            cmap='coolwarm')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"the figure above shows that most of the pearson correlations between the numerical data are close to zero, in fact is between 0 and 0.2. That means that most of the numerical data are almost uncorrelated between them."},{"metadata":{},"cell_type":"markdown","source":"#### Most correlated features:"},{"metadata":{"trusted":true},"cell_type":"code","source":"s = corr.unstack().drop_duplicates()\nso = s.sort_values(kind=\"quicksort\")\nso = so.drop_duplicates()\n\nprint(\"Top most highly positive correlated features:\")\nprint(so[(so<1) & (so>0.5)].sort_values(ascending=False))\n\nprint()\n\nprint(\"Top most highly megative correlated features:\")\nprint(so[(so < - 0.005)])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### EDA Summary\n\n- We have 200 features that are mostly uncorrelated between them\n- 200 numerical features that their histograms have a shape like the one of a normal distribution"},{"metadata":{},"cell_type":"markdown","source":"## Machine Learning Modeling"},{"metadata":{},"cell_type":"markdown","source":"![](https://cmci.colorado.edu/classes/INFO-4604/fa17/wordcloud.png)\n[image-source](https://cmci.colorado.edu/classes/INFO-4604/fa17/wordcloud.png)"},{"metadata":{},"cell_type":"markdown","source":"### Feature Engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape, test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# special thanks to https://www.kaggle.com/gpreda/santander-eda-and-prediction\n\ngc.collect();\nfor df in [test, train]:\n    df['sum'] = df[numerical_features].sum(axis=1)  \n    df['min'] = df[numerical_features].min(axis=1)\n    df['max'] = df[numerical_features].max(axis=1)\n    df['mean'] = df[numerical_features].mean(axis=1)\n    df['std'] = df[numerical_features].std(axis=1)\n    df['skew'] = df[numerical_features].skew(axis=1)\n    df['kurt'] = df[numerical_features].kurtosis(axis=1)\n    df['med'] = df[numerical_features].median(axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = train['target']\nX = train.drop(['target', \"ID_code\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_stats_df = pd.DataFrame(columns=[\"clf_name\", \"F1-score\", \"auc-score\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def xgboost_all_purpose(X, y, type_of_training, name, num_of_folds=3, params=None, max_early_stopping = 100):\n    \n    from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n    from collections import Counter\n    from sklearn.metrics import accuracy_score\n    from sklearn.metrics import precision_score\n    from sklearn.metrics import recall_score\n    from sklearn.metrics import f1_score\n    from sklearn.metrics import classification_report\n    from sklearn.metrics import roc_auc_score\n    import scikitplot as skplt\n    import time\n    import random\n    \n    import xgboost as xgb\n    \n    global clf_stats_df\n    \n    if params is None:\n        params = dict()\n        params[\"learning_rate\"] = 0.1\n        params[\"n_estimators\"] = 500\n        params[\"max_depth\"] = 2\n        params[\"min_child_weight\"] = 1\n        params[\"gamma\"] = 0\n        params[\"subsample\"] = 1\n        params[\"colsample_bytree\"] = 1\n        params[\"colsample_bylevel\"] = 1\n        params[\"reg_alpha\"] = 0\n        params[\"reg_lambda\"] = 1\n        params[\"scale_pos_weight\"] = np.round(y.value_counts()[0] / y.value_counts()[1],3)\n        params[\"max_delta_step\"] = 1\n    \n    print(\"params\", params)\n    print(\"max_early_stopping:\", max_early_stopping)\n    \n    if type_of_training == \"baseline\":\n        \n        print(\"baseline\")\n        \n        # create a 70/30 stratified split of the data \n        xtrain, xvalid, ytrain, yvalid = train_test_split(X, y, stratify = y, random_state=42, test_size=0.3)\n    \n        import xgboost as xgb\n\n        start_time = time.time()\n        \n        predictions_probas_list = np.zeros([len(yvalid), 2])\n        predictions_test = np.zeros(len(test))\n        num_fold = 0\n        #feature_importance_df = pd.DataFrame()\n        \n        folds = StratifiedKFold(n_splits=num_of_folds, shuffle=False, random_state = 42)\n        \n        for train_index, valid_index in folds.split(xtrain, ytrain):\n            xtrain_stra, xvalid_stra = xtrain.iloc[train_index,:], xtrain.iloc[valid_index,:]\n            ytrain_stra, yvalid_stra = ytrain.iloc[train_index], ytrain.iloc[valid_index]\n            \n            print()\n            print(\"Stratified Fold:\", num_fold)\n            num_fold = num_fold + 1\n            print()\n            \n            clf_stra_xgb = xgb.XGBClassifier(learning_rate=params[\"learning_rate\"], \n                                    n_estimators=params[\"n_estimators\"], \n                                    max_depth=params[\"max_depth\"],\n                                    min_child_weight=params[\"min_child_weight\"],\n                                    gamma=params[\"gamma\"],\n                                    subsample=params[\"subsample\"],\n                                    colsample_bytree=params[\"colsample_bytree\"],\n                                    colsample_bylevel=params[\"colsample_bylevel\"],\n                                    objective= 'binary:logistic',\n                                    nthread=-1,\n                                    scale_pos_weight=params[\"scale_pos_weight\"],\n                                    reg_alpha = params[\"reg_alpha\"],\n                                    reg_lambda = params[\"reg_lambda\"],\n                                    max_delta_step = params[\"max_delta_step\"],\n                                    seed=42)\n\n            clf_stra_xgb.fit(xtrain_stra, ytrain_stra, eval_set=[(xtrain_stra, ytrain_stra), (xvalid_stra, yvalid_stra)], \n                        early_stopping_rounds=max_early_stopping, eval_metric='auc', verbose=100)\n            \n            #fold_importance_df = pd.DataFrame()\n            #fold_importance_df[\"feature\"] = pd.DataFrame.from_dict(data=clf_stra_xgb.get_fscore(), orient=\"index\", columns=[\"FScore\"])[\"FScore\"].index\n            #fold_importance_df[\"fscore\"] = pd.DataFrame.from_dict(data=clf_stra_xgb.get_fscore(), orient=\"index\", columns=[\"FScore\"])[\"FScore\"].values\n            #fold_importance_df[\"fold\"] = n_fold + 1\n            #feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n\n            predictions = clf_stra_xgb.predict(xvalid)\n            predictions_probas = clf_stra_xgb.predict_proba(xvalid)\n            predictions_probas_list += predictions_probas/num_of_folds\n            \n            predictions_test += clf_stra_xgb.predict_proba(test.drop(\"ID_code\", axis=\"columns\")[xtrain.columns])[:,1]/num_of_folds\n            \n        \n        predictions = np.argmax(predictions_probas, axis=1)\n\n        print()\n        print(classification_report(yvalid, predictions))\n\n        print()\n        print(\"CV f1_score\", f1_score(yvalid, predictions, average = \"macro\"))\n        \n        print()\n        print(\"CV roc_auc_score\", roc_auc_score(yvalid, predictions_probas_list[:,1], average = \"macro\"))\n        \n        print()\n        print(\"elapsed time in seconds: \", time.time() - start_time)\n        \n        sns.set(rc={'figure.figsize':(8,8)})\n        skplt.metrics.plot_confusion_matrix(yvalid, predictions, normalize=True)\n        \n        sns.set(rc={'figure.figsize':(8,8)})\n        skplt.metrics.plot_roc(yvalid, predictions_probas)\n        \n        sns.set(rc={'figure.figsize':(8,8)})\n        skplt.metrics.plot_ks_statistic(yvalid, predictions_probas)\n        \n        sns.set(rc={'figure.figsize':(8,8)})\n        skplt.metrics.plot_precision_recall(yvalid, predictions_probas)\n        \n        sns.set(rc={'figure.figsize':(8,8)})\n        skplt.metrics.plot_cumulative_gain(yvalid, predictions_probas)\n\n        sns.set(rc={'figure.figsize':(8,8)})\n        skplt.metrics.plot_lift_curve(yvalid, predictions_probas)\n        \n        sns.set(rc={'figure.figsize':(12, 38)})\n        xgb.plot_importance(clf_stra_xgb, title='Feature importance', xlabel='F score', ylabel='Features')\n\n        clf_stats_df = clf_stats_df.append({\"clf_name\": name,\n                             \"F1-score\":f1_score(yvalid, predictions, average = \"macro\"),\n                             \"auc-score\": roc_auc_score(yvalid, predictions_probas[:,1], average = \"macro\")}, ignore_index=True)\n        \n        print()\n        gc.collect();\n        return clf_stra_xgb, predictions_test\n\n    \n    elif type_of_training == \"oversampling\":\n        \n        print(\"oversampling\")\n        #### resampling techniques:\n        from imblearn.over_sampling import SMOTE, ADASYN, RandomOverSampler\n\n        # create a 70/30 split of the data \n        xtrain, xvalid, ytrain, yvalid = train_test_split(X, y, stratify = y, random_state=42, test_size=0.3)\n\n        # RandomOverSampler\n        ros = RandomOverSampler(random_state=42)\n        X_resampled, y_resampled = ros.fit_resample(xtrain, ytrain)\n        \n        from collections import Counter\n        print(sorted(Counter(y_resampled).items()))\n        \n        xtrain=pd.DataFrame(X_resampled, columns = X.columns)\n        ytrain = y_resampled\n        del X_resampled\n        del y_resampled\n        \n        predictions_probas_list = np.zeros([len(yvalid), 2])\n        predictions_test = np.zeros(len(test))\n        num_fold = 0        \n\n        start_time = time.time()\n        \n        folds = StratifiedKFold(n_splits=num_of_folds, shuffle=False, random_state = 42)\n        \n        for train_index, valid_index in folds.split(xtrain, ytrain):\n            xtrain_stra, xvalid_stra = xtrain.iloc[train_index,:], xtrain.iloc[valid_index,:]\n            ytrain_stra, yvalid_stra = ytrain[train_index], ytrain[valid_index]\n            \n            print()\n            print(\"Fold:\", num_fold)\n            num_fold = num_fold + 1\n            print()\n\n            clf_ros_xgb = xgb.XGBClassifier(learning_rate=params[\"learning_rate\"], \n                                        n_estimators=params[\"n_estimators\"], \n                                        max_depth=params[\"max_depth\"],\n                                        min_child_weight=params[\"min_child_weight\"],\n                                        gamma=params[\"gamma\"],\n                                        subsample=params[\"subsample\"],\n                                        colsample_bytree=params[\"colsample_bytree\"],\n                                        colsample_bylevel=params[\"colsample_bylevel\"],\n                                        objective= 'binary:logistic',\n                                        nthread=-1,\n                                        scale_pos_weight=params[\"scale_pos_weight\"],\n                                        reg_alpha = params[\"reg_alpha\"],\n                                        reg_lambda = params[\"reg_lambda\"],\n                                        max_delta_step = params[\"max_delta_step\"],\n                                        seed=42)\n\n            clf_ros_xgb.fit(xtrain_stra, ytrain_stra, eval_set=[(xtrain_stra, ytrain_stra), (xvalid_stra, yvalid_stra)], \n                    early_stopping_rounds=max_early_stopping, eval_metric='auc', verbose=100)\n\n            predictions = clf_ros_xgb.predict(xvalid)\n            predictions_probas = clf_ros_xgb.predict_proba(xvalid)\n            predictions_probas_list += predictions_probas/num_of_folds  \n            \n            predictions_test += clf_ros_xgb.predict_proba(test.drop(\"ID_code\", axis=\"columns\")[xtrain.columns])[:,1]/num_of_folds\n            \n        predictions = np.argmax(predictions_probas, axis=1)\n            \n        print()\n        print(classification_report(yvalid, predictions))\n\n        print()\n        print(\"f1_score\", f1_score(yvalid, predictions, average = \"macro\"))\n        \n        print()\n        print(\"roc_auc_score\", roc_auc_score(yvalid, predictions_probas[:,1], average = \"macro\"))\n\n        print()\n        print(\"elapsed time in seconds: \", time.time() - start_time)\n        \n        sns.set(rc={'figure.figsize':(8, 8)})\n        skplt.metrics.plot_confusion_matrix(yvalid, predictions, normalize=True)\n        \n        skplt.metrics.plot_roc(yvalid, predictions_probas)\n        \n        skplt.metrics.plot_precision_recall(yvalid, predictions_probas)\n        \n        sns.set(rc={'figure.figsize':(12, 38)})\n        xgb.plot_importance(clf_ros_xgb, title='Feature importance', xlabel='F score', ylabel='Features')\n        \n        clf_stats_df = clf_stats_df.append({\"clf_name\": name,\n                             \"F1-score\":f1_score(yvalid, predictions, average = \"macro\"),\n                             \"auc-score\": roc_auc_score(yvalid, predictions_probas[:,1], average = \"macro\")}, ignore_index=True)\n\n        print()\n        gc.collect();\n        return clf_ros_xgb, predictions_test\n    \n    # still needs some work to work\n    elif type_of_training == \"smote\":\n        print(\"smote\")\n        #### resampling techniques, I will use Synthetic minority:\n        from imblearn.over_sampling import SMOTE, ADASYN, RandomOverSampler\n\n        # create a 70/30 split of the data \n        xtrain, xvalid, ytrain, yvalid = train_test_split(X, y, stratify = y, random_state=42, test_size=0.3)\n\n        # SMOTE\n        smote = SMOTE(random_state=42)\n        X_resampled, y_resampled = smote.fit_resample(xtrain, ytrain)\n        \n        from collections import Counter\n        print(sorted(Counter(y_resampled).items()))\n        \n        xtrain=pd.DataFrame(X_resampled, columns = X.columns)\n        ytrain = y_resampled\n\n        start_time = time.time()\n\n        clf_smote_xgb = xgb.XGBClassifier(learning_rate=params[\"learning_rate\"], \n                                    n_estimators=params[\"n_estimators\"], \n                                    max_depth=params[\"max_depth\"],\n                                    min_child_weight=params[\"min_child_weight\"],\n                                    gamma=params[\"gamma\"],\n                                    subsample=params[\"subsample\"],\n                                    colsample_bytree=params[\"colsample_bytree\"],\n                                    objective= 'binary:logistic',\n                                    nthread=-1,\n                                    scale_pos_weight=params[\"scale_pos_weight\"],\n                                    reg_alpha = params[\"reg_alpha\"],\n                                    reg_lambda = params[\"reg_lambda\"],\n                                    max_delta_step = params[\"max_delta_step\"],\n                                    seed=42)\n\n        clf_smote_xgb.fit(xtrain, ytrain, eval_set=[(xtrain, ytrain), (xvalid, yvalid)], \n                    early_stopping_rounds=max_early_stopping, eval_metric='auc', verbose=100)\n\n        predictions = clf_smote_xgb.predict(xvalid)\n        predictions_probas = clf_smote_xgb.predict_proba(xvalid)\n\n        print()\n        print(classification_report(yvalid, predictions))\n\n        print()\n        print(\"f1_score\", f1_score(yvalid, predictions, average = \"macro\"))\n        \n        print()\n        print(\"roc_auc_score\", roc_auc_score(yvalid, predictions_probas[:,1], average = \"macro\"))\n\n        print()\n        print(\"elapsed time in seconds: \", time.time() - start_time)\n        \n        sns.set(rc={'figure.figsize':(8,8)})\n        skplt.metrics.plot_confusion_matrix(yvalid, predictions, normalize=True)\n        \n        sns.set(rc={'figure.figsize':(8,8)})\n        skplt.metrics.plot_roc(yvalid, predictions_probas)\n        \n        sns.set(rc={'figure.figsize':(8,8)})\n        skplt.metrics.plot_ks_statistic(yvalid, predictions_probas)\n        \n        sns.set(rc={'figure.figsize':(8,8)})\n        skplt.metrics.plot_precision_recall(yvalid, predictions_probas)\n        \n        sns.set(rc={'figure.figsize':(8,8)})\n        skplt.metrics.plot_cumulative_gain(yvalid, predictions_probas)\n\n        sns.set(rc={'figure.figsize':(8,8)})\n        skplt.metrics.plot_lift_curve(yvalid, predictions_probas)\n        \n        sns.set(rc={'figure.figsize':(12, 38)})\n        xgb.plot_importance(clf_smote_xgb, title='Feature importance', xlabel='F score', ylabel='Features')\n        \n        clf_stats_df = clf_stats_df.append({\"clf_name\": name,\n                             \"F1-score\":f1_score(yvalid, predictions, average = \"macro\"),\n                             \"auc-score\": roc_auc_score(yvalid, predictions_probas[:,1], average = \"macro\")}, ignore_index=True)\n\n        print()\n        gc.collect();\n        return clf_smote_xgb\n    \n    # still needs some work to work\n    elif type_of_training == \"undersampling\":\n        print(\"undersampling\")\n        #### resampling techniques:\n        from imblearn.under_sampling import RandomUnderSampler\n\n        # create a 70/30 split of the data \n        xtrain, xvalid, ytrain, yvalid = train_test_split(X, y, random_state=42, test_size=0.3)\n\n        # RandomUnderSampler\n        rus = RandomUnderSampler(random_state=42)\n        X_resampled, y_resampled = rus.fit_resample(xtrain, ytrain)\n        \n        print(sorted(Counter(y_resampled).items()))\n        \n        xtrain=pd.DataFrame(X_resampled, columns = X.columns)\n        ytrain = y_resampled\n\n        start_time = time.time()\n\n        clf_rus_xgb = xgb.XGBClassifier(learning_rate=params[\"learning_rate\"], \n                                    n_estimators=params[\"n_estimators\"], \n                                    max_depth=params[\"max_depth\"],\n                                    min_child_weight=params[\"min_child_weight\"],\n                                    gamma=params[\"gamma\"],\n                                    subsample=params[\"subsample\"],\n                                    colsample_bytree=params[\"colsample_bytree\"],\n                                    objective= 'binary:logistic',\n                                    nthread=-1,\n                                    scale_pos_weight=params[\"scale_pos_weight\"],\n                                    reg_alpha = params[\"reg_alpha\"],\n                                    reg_lambda = params[\"reg_lambda\"],\n                                    max_delta_step = params[\"max_delta_step\"],\n                                    seed=42)\n\n        clf_rus_xgb.fit(xtrain, ytrain, eval_set=[(xtrain, ytrain), (xvalid, yvalid)], \n                    early_stopping_rounds=max_early_stopping, eval_metric='auc', verbose=100)\n\n        predictions = clf_rus_xgb.predict(xvalid)\n        predictions_probas = clf_rus_xgb.predict_proba(xvalid)\n        \n        \n        print()\n        print(classification_report(yvalid, predictions))\n\n        print()\n        print(\"f1_score\", f1_score(yvalid, predictions, average = \"macro\"))\n        \n        print()\n        print(\"roc_auc_score\", roc_auc_score(yvalid, predictions_probas[:,1], average = \"macro\"))\n\n        print()\n        print(\"elapsed time in seconds: \", time.time() - start_time)\n        \n        sns.set(rc={'figure.figsize':(8,8)})\n        skplt.metrics.plot_confusion_matrix(yvalid, predictions, normalize=True)\n        \n        sns.set(rc={'figure.figsize':(8,8)})\n        skplt.metrics.plot_roc(yvalid, predictions_probas)\n        \n        sns.set(rc={'figure.figsize':(8,8)})\n        skplt.metrics.plot_ks_statistic(yvalid, predictions_probas)\n        \n        sns.set(rc={'figure.figsize':(8,8)})\n        skplt.metrics.plot_precision_recall(yvalid, predictions_probas)\n        \n        sns.set(rc={'figure.figsize':(8,8)})\n        skplt.metrics.plot_cumulative_gain(yvalid, predictions_probas)\n\n        sns.set(rc={'figure.figsize':(8,8)})\n        skplt.metrics.plot_lift_curve(yvalid, predictions_probas)\n        \n        sns.set(rc={'figure.figsize':(12, 38)})\n        xgb.plot_importance(clf_rus_xgb, title='Feature importance', xlabel='F score', ylabel='Features')\n        \n        clf_stats_df = clf_stats_df.append({\"clf_name\": name,\n                             \"F1-score\":f1_score(yvalid, predictions, average = \"macro\"),\n                             \"auc-score\": roc_auc_score(yvalid, predictions_probas[:,1], average = \"macro\")}, ignore_index=True)\n\n        print()\n        gc.collect();\n        #return clf_rus_xgb, predictions, predictions_probas\n        return clf_rus_xgb\n    \n    elif type_of_training == \"augmentation\":\n        \n        # the main idea here is to reducing the imbalance ratio from 9:1 to 3:1\n        print(\"augmentation\")\n        \n        # create a 70/30 split of the data \n        xtrain, xvalid, ytrain, yvalid = train_test_split(X, y, stratify=y, random_state=42, test_size=0.3)\n\n        print(\"ytrain target values count before augmentation:\\n\", sorted(Counter(ytrain).items()))\n\n        # Augmenting both minority and majority classes via RandomOverSampler by 3 times\n        X_y = pd.DataFrame(xtrain, columns=X.columns)\n        X_y[\"target\"] = ytrain\n        X_y = X_y.sample(frac=3, replace=True)\n        X_y.target.value_counts()\n        ytrain = X_y['target']\n        print(\"ytrain target values count after oversampling:\\n\",sorted(Counter(ytrain).items()))\n        xtrain = X_y.drop(['target'], axis=1)\n        del X_y\n\n        from imblearn.under_sampling import RandomUnderSampler\n\n        # reducing the majority class almost back to its original form\n        rus = RandomUnderSampler(sampling_strategy=0.33, random_state=42)\n        X_resampled, y_resampled = rus.fit_resample(xtrain, ytrain)\n\n        print(\"ytrain target values count after Augmentation:\\n\",sorted(Counter(y_resampled).items()))\n        \n        xtrain=pd.DataFrame(X_resampled, columns = X.columns)\n        ytrain = y_resampled\n        \n        del X_resampled\n        del y_resampled\n\n        start_time = time.time()\n        \n        predictions_probas_list = np.zeros([len(yvalid), 2])\n        predictions_test = np.zeros(len(test))\n        num_fold = 0\n        #feature_importance_df = pd.DataFrame()\n        \n        folds = StratifiedKFold(n_splits=num_of_folds, shuffle=False, random_state = 42)\n        \n        for train_index, valid_index in folds.split(xtrain, ytrain):\n            xtrain_stra, xvalid_stra = xtrain.iloc[train_index,:], xtrain.iloc[valid_index,:]\n            ytrain_stra, yvalid_stra = ytrain[train_index], ytrain[valid_index]\n            \n            print()\n            print(\"Stratified Fold:\", num_fold)\n            num_fold = num_fold + 1\n            print()\n\n            clf_aug_xgb = xgb.XGBClassifier(learning_rate=params[\"learning_rate\"], \n                                        n_estimators=params[\"n_estimators\"], \n                                        max_depth=params[\"max_depth\"],\n                                        min_child_weight=params[\"min_child_weight\"],\n                                        gamma=params[\"gamma\"],\n                                        subsample=params[\"subsample\"],\n                                        colsample_bytree=params[\"colsample_bytree\"],\n                                        colsample_bylevel=params[\"colsample_bylevel\"],\n                                        objective= 'binary:logistic',\n                                        nthread=-1,\n                                        scale_pos_weight=params[\"scale_pos_weight\"],\n                                        reg_alpha = params[\"reg_alpha\"],\n                                        reg_lambda = params[\"reg_lambda\"],\n                                        max_delta_step = params[\"max_delta_step\"],\n                                        seed=42)\n\n            clf_aug_xgb.fit(xtrain_stra, ytrain_stra, eval_set=[(xtrain_stra, ytrain_stra), (xvalid_stra, yvalid_stra)], \n                    early_stopping_rounds=max_early_stopping, eval_metric='auc', verbose=100)\n            \n            #fold_importance_df = pd.DataFrame()\n            #fold_importance_df[\"feature\"] = pd.DataFrame.from_dict(data=clf_aug_xgb.get_fscore(), orient=\"index\", columns=[\"FScore\"])[\"FScore\"].index\n            #fold_importance_df[\"fscore\"] = pd.DataFrame.from_dict(data=clf_aug_xgb.get_fscore(), orient=\"index\", columns=[\"FScore\"])[\"FScore\"].values\n            #fold_importance_df[\"fold\"] = n_fold + 1\n            #feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n\n            predictions = clf_aug_xgb.predict(xvalid)\n            predictions_probas = clf_aug_xgb.predict_proba(xvalid)\n            predictions_probas_list += predictions_probas/num_of_folds  \n            \n            predictions_test += clf_aug_xgb.predict_proba(test.drop(\"ID_code\", axis=\"columns\")[xtrain.columns])[:,1]/num_of_folds\n            \n        \n        predictions = np.argmax(predictions_probas, axis=1)\n\n        print()\n        print(classification_report(yvalid, predictions))\n\n        print()\n        print(\"CV f1_score\", f1_score(yvalid, predictions, average = \"macro\"))\n        \n        print()\n        print(\"CV roc_auc_score\", roc_auc_score(yvalid, predictions_probas[:,1], average = \"macro\"))\n\n        print()\n        print(\"elapsed time in seconds: \", time.time() - start_time)\n        \n        sns.set(rc={'figure.figsize':(8,8)})\n        skplt.metrics.plot_confusion_matrix(yvalid, predictions, normalize=True)\n        \n        sns.set(rc={'figure.figsize':(8,8)})\n        skplt.metrics.plot_roc(yvalid, predictions_probas)\n        \n        sns.set(rc={'figure.figsize':(8,8)})\n        skplt.metrics.plot_ks_statistic(yvalid, predictions_probas)\n        \n        sns.set(rc={'figure.figsize':(8,8)})\n        skplt.metrics.plot_precision_recall(yvalid, predictions_probas)\n        \n        sns.set(rc={'figure.figsize':(8,8)})\n        skplt.metrics.plot_cumulative_gain(yvalid, predictions_probas)\n\n        sns.set(rc={'figure.figsize':(8,8)})\n        skplt.metrics.plot_lift_curve(yvalid, predictions_probas)\n        \n        sns.set(rc={'figure.figsize':(12, 38)})\n        xgb.plot_importance(clf_aug_xgb, title='Feature importance', xlabel='F score', ylabel='Features')\n        \n        clf_stats_df = clf_stats_df.append({\"clf_name\": name,\n                             \"F1-score\":f1_score(yvalid, predictions, average = \"macro\"),\n                             \"auc-score\": roc_auc_score(yvalid, predictions_probas[:,1], average = \"macro\")}, ignore_index=True)\n\n        print()\n        gc.collect();\n        #return clf_rus_xgb, predictions, predictions_probas\n        return clf_aug_xgb, predictions_test\n    \n    else:\n        print(\"Please specify for the argument 'type_of_training'one of the following parameters: (baseline, oversampling, smote, undersampling, augmentation)\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type_of_training = \"oversampling\"\nnum_of_folds = 2 ### must be more than 2\nclf_xgb, predictions_test_xgb = xgboost_all_purpose(X,y, num_of_folds = num_of_folds, type_of_training =type_of_training,  max_early_stopping = 100, name=\"clf_xgb\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Test set predictions probabilities histogram"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(rc={'figure.figsize':(8,8)})\nplt.hist(predictions_test_xgb)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature Selection - Permutation Importance"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\n\ngc.collect();\nxtrain, xvalid, ytrain, yvalid = train_test_split(X, y, stratify = y, test_size=0.3, random_state=42)\n\n\nrfc_model = RandomForestClassifier(random_state=42, class_weight={0: 1, 1: np.round(y.value_counts()[0] / y.value_counts()[1],3)}).fit(xtrain, ytrain)\n\nimport eli5\nfrom eli5.sklearn import PermutationImportance\n\nperm = PermutationImportance(rfc_model, random_state=42).fit(xvalid, yvalid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eli5.show_weights(perm, feature_names = xvalid.columns.tolist(), top=100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Select top 100 features after permutation importance:"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import SelectFromModel\n\nmax_selected_features = 100\nsel = SelectFromModel(perm, max_features = max_selected_features, prefit=True)\nX_trans = sel.transform(X)\n\nfeature_idx = sel.get_support()\nselected_feature_names = X.columns[feature_idx]\n\ngc.collect();\nX_fs = X[selected_feature_names]\nX_fs.shape\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### XGBoost Training after Feature Selection"},{"metadata":{"trusted":true},"cell_type":"code","source":"num_of_folds = 2 ### must be more than 2\n\nfs_clf_xgb, predictions_test_fs_xgb = xgboost_all_purpose(X_fs,y, type_of_training =type_of_training, num_of_folds = num_of_folds, max_early_stopping= 100, name=\"fs_clf_xgb\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Test set prediction probabilities distribution after feature selection"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(rc={'figure.figsize':(8,8)})\nplt.hist(predictions_test_fs_xgb)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_stats_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I believe that Feature selection worsen the auc-score, so I will not use it for the future experiments."},{"metadata":{},"cell_type":"markdown","source":"## ML Bayesian Optimization Tuning"},{"metadata":{"trusted":true},"cell_type":"code","source":"if type_of_training == \"baseline\":\n    \n    print(\"baseline\")\n    xtrain, xvalid, ytrain, yvalid = train_test_split(X, y, stratify = y, random_state=42, test_size=0.3)\n\nelif type_of_training == \"oversampling\":\n    \n    print(\"oversampling\")\n    \n    from imblearn.over_sampling import SMOTE, ADASYN, RandomOverSampler\n\n    # create a 70/30 split of the data \n    xtrain, xvalid, ytrain, yvalid = train_test_split(X, y, stratify = y, random_state=42, test_size=0.3)\n\n    # RandomOverSampler\n    ros = RandomOverSampler(random_state=42)\n    X_resampled, y_resampled = ros.fit_resample(xtrain, ytrain)\n\n    from collections import Counter\n    print(sorted(Counter(y_resampled).items()))\n\n    xtrain=pd.DataFrame(X_resampled, columns = X.columns)\n    ytrain = y_resampled\n    del X_resampled\n    del y_resampled\n\n    \nelif type_of_training == \"augmentation\":\n    \n    # the main idea here is to reducing the imbalance ratio from 9:1 to 3:1\n    print(\"augmentation\")\n    \n    from collections import Counter\n\n    # create a 70/30 split of the data \n    xtrain, xvalid, ytrain, yvalid = train_test_split(X, y, stratify = y, random_state=42, test_size=0.3)\n\n    print(\"ytrain target values count before augmentation:\\n\", sorted(Counter(ytrain).items()))\n\n    # Augmenting both minority and majority classes via RandomOverSampler by 3 times\n    X_y = pd.DataFrame(xtrain, columns=X.columns)\n    X_y[\"target\"] = ytrain\n    X_y = X_y.sample(frac=3, replace=True)\n    X_y.target.value_counts()\n    ytrain = X_y['target']\n    print(\"ytrain target values count after oversampling:\\n\",sorted(Counter(ytrain).items()))\n    xtrain = X_y.drop(['target'], axis=1)\n    del X_y\n\n    from imblearn.under_sampling import RandomUnderSampler\n\n    # reducing the majority class almost back to its original form\n    rus = RandomUnderSampler(sampling_strategy=0.33, random_state=42)\n    X_resampled, y_resampled = rus.fit_resample(xtrain, ytrain)\n\n    print(\"ytrain target values count after Augmentation:\\n\",sorted(Counter(y_resampled).items()))\n\n    xtrain=pd.DataFrame(X_resampled, columns = X.columns)\n    ytrain = y_resampled\n\n    del X_resampled\n    del y_resampled\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from skopt import BayesSearchCV\nfrom sklearn.model_selection import StratifiedKFold\nimport xgboost as xgb\n\n# Classifier\nbayes_cv_tuner = BayesSearchCV(\n    estimator = xgb.XGBClassifier(\n        nthread = -1,\n        objective = 'binary:logistic',\n        eval_metric = 'auc',\n        silent=1,\n        tree_method='auto'\n    ),\n    search_spaces = {\n        'learning_rate': (0.01, 1.0, 'log-uniform'),\n        'min_child_weight': (0, 10),\n        'n_estimators': (50, 100),\n        'max_depth': (0, 10),\n        'gamma': (1e-4, 20, 'log-uniform'),\n        'subsample': (0.01, 1.0, 'uniform'),\n        'colsample_bytree': (0.01, 1.0, 'uniform'),\n        'colsample_bylevel': (0.01, 1.0, 'uniform'),\n        'reg_lambda': (1e-4, 100, 'log-uniform'),\n        'reg_alpha': (1e-4, 1.0, 'log-uniform'),\n        'max_delta_step': (0, 20),\n        'scale_pos_weight': (1e-2, 10, 'log-uniform')\n    },    \n    scoring = 'roc_auc',\n    cv = StratifiedKFold(\n        n_splits=3,\n        shuffle=True,\n        random_state=42\n    ),\n    n_jobs = 1,\n    n_iter = 10,   \n    verbose = 0,\n    refit = True,\n    random_state = 42\n)\n\ndef status_print(optim_result):\n    \"\"\"Status callback durring bayesian hyperparameter search\"\"\"\n    \n    # Get all the models tested so far in DataFrame format\n    all_models = pd.DataFrame(bayes_cv_tuner.cv_results_)    \n    \n    # Get current parameters and the best parameters    \n    best_params = pd.Series(bayes_cv_tuner.best_params_)\n    print('Model #{}\\nBest ROC-AUC: {}\\nBest params: {}\\n'.format(\n        len(all_models),\n        np.round(bayes_cv_tuner.best_score_, 4),\n        bayes_cv_tuner.best_params_\n    ))\n    \n    ### Save all model results\n    #clf_name = bayes_cv_tuner.estimator.__class__.__name__\n    #all_models.to_csv(clf_name+\"_cv_results.csv\")\n    \n# Fit the model\nresult = bayes_cv_tuner.fit(xtrain, ytrain, callback=status_print)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result.best_params_['n_estimators'] = 4000\n\n#params['learning_rate'] = 0.01\n#params['scale_pos_weight'] = np.round(y.value_counts()[0] / y.value_counts()[1],3)\n#params['max_delta_step'] = 1\n\nresult.best_params_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Retraining after tuning"},{"metadata":{"trusted":true},"cell_type":"code","source":"num_of_folds = 5 ### must be more than 2\n\ntuned_clf_xgb, predictions_test_tuned_xgb = xgboost_all_purpose(X,y, type_of_training = type_of_training, num_of_folds=num_of_folds, params = result.best_params_, max_early_stopping = 400, name=\"tuned_clf_xgb\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Test set predictions probabilities without Feature Selection and with Tuning"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(rc={'figure.figsize':(8,8)})\nplt.hist(predictions_test_tuned_xgb)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_stats_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## ML Blends\n** To be updated **"},{"metadata":{},"cell_type":"markdown","source":"## Preparing for submmission"},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect();\nsubmission = pd.read_csv('../input/sample_submission.csv')\nsubmission['target'] = predictions_test_xgb\nsubmission.to_csv('clf_xgb.csv', index=False)\n\n\ngc.collect();\nsubmission = pd.read_csv('../input/sample_submission.csv')\nsubmission['target'] = predictions_test_fs_xgb\nsubmission.to_csv('fs_clf_xgb.csv', index=False)\n\n\ngc.collect();\nsubmission = pd.read_csv('../input/sample_submission.csv')\nsubmission['target'] = predictions_test_tuned_xgb\nsubmission.to_csv('tuned_clf_xgb.csv', index=False)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Conclusion\nWe can see from EDA and ML Modeling that class #1 is very unbalanced and difficult to identified and classified."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}