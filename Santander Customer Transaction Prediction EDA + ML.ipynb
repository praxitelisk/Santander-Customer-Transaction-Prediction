{"cells":[{"metadata":{},"cell_type":"markdown","source":"![](https://www.santander.co.uk/themes/custom/santander_web18/logo.svg)\n\n[image-source](https://www.santander.co.uk/themes/custom/santander_web18/logo.svg)\n\n"},{"metadata":{},"cell_type":"markdown","source":"## Main outline"},{"metadata":{},"cell_type":"markdown","source":"<img src=\"data:image/png;base64,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\" style=\"cursor:pointer;max-width:100%;\" onclick=\"(function(img){if(img.wnd!=null&&!img.wnd.closed){img.wnd.focus();}else{var r=function(evt){if(evt.data=='ready'&&evt.source==img.wnd){img.wnd.postMessage(decodeURIComponent(img.getAttribute('src')),'*');window.removeEventListener('message',r);}};window.addEventListener('message',r);img.wnd=window.open('https://www.draw.io/?client=1&lightbox=1&edit=_blank');}})(this);\"/>"},{"metadata":{},"cell_type":"markdown","source":"## Exploratory Data Analysis\n\n![](http://blog.k2analytics.co.in/wp-content/uploads/2016/12/Exploratory_Data_Analysis.png)\n\n[image-source](http://blog.k2analytics.co.in/wp-content/uploads/2016/12/Exploratory_Data_Analysis.png)"},{"metadata":{},"cell_type":"markdown","source":"### Importing the dataset"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.style.use('fivethirtyeight')\n\nimport gc\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape, test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"At first glance we have many uncharacterized numerical features, their names has the prefix \"var_\" and they are 200 in numbers. There are so many variables that some histograms will shed light to their numerical appearance."},{"metadata":{"trusted":true},"cell_type":"code","source":"train.target.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['target'].value_counts().plot(kind=\"pie\", figsize=(12,9), colormap=\"coolwarm\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we have a typical imbalanced dataset."},{"metadata":{},"cell_type":"markdown","source":"#### check for missing data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isna().sum().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.isna().sum().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have no NA values which is very nice!!"},{"metadata":{},"cell_type":"markdown","source":"#### Splitting the numerical features"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe()\ngc.collect();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_features = train.columns[2:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Distributions columns')\nplt.figure(figsize=(30, 185))\nfor i, col in enumerate(numerical_features):\n    plt.subplot(50, 4, i + 1)\n    plt.hist(train[col]) \n    plt.title(col)\ngc.collect();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Almost all features shows a normal distribution shape. Lets see the distributions for for all numerical features per each class."},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Distributions columns')\nplt.figure(figsize=(30, 185))\nfor i, col in enumerate(numerical_features):\n    plt.subplot(50, 4, i + 1)\n    plt.hist(train[train[\"target\"] == 0][col], alpha=0.5, label='0', color='b')\n    plt.hist(train[train[\"target\"] == 1][col], alpha=0.5, label='1', color='r')    \n    plt.title(col)\ngc.collect();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20, 8))\ntrain[numerical_features].mean().plot('hist');\nplt.title('Mean Frequency');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20, 8))\ntrain[numerical_features].median().plot('hist');\nplt.title('Median Frequency');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20, 8))\ntrain[numerical_features].std().plot('hist');\nplt.title('Standard Deviation Frequency');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Most of the distributions show small std. deviations, and very few more than 20. Maybe a log transformation or a scaling technique to all features will alter the graph above to a normal one. "},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20, 8))\ntrain[numerical_features].skew().plot('hist');\nplt.title('Skewness Frequency');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20, 8))\ntrain[numerical_features].kurt().plot('hist');\nplt.title('Kurtosis Frequency');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Both Skewness and Kurtosis show that the features distributions are like a normal one."},{"metadata":{},"cell_type":"markdown","source":"#### correlations between numerical data"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(rc={'figure.figsize':(20,28)})\n\n# Compute the correlation matrix\ncorr = train[numerical_features].corr()\n\n# Generate a mask for the upper triangle\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\nsns.heatmap(corr, mask=mask, \n            #annot=True, \n            #fmt=\".2f\", \n            cmap='coolwarm')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"the figure above shows that most of the pearson correlations between the numerical data are close to zero, in fact is between 0 and 0.2. That means that most of the numerical data are almost uncorrelated between them."},{"metadata":{},"cell_type":"markdown","source":"#### Most correlated features:"},{"metadata":{"trusted":true},"cell_type":"code","source":"s = corr.unstack().drop_duplicates()\nso = s.sort_values(kind=\"quicksort\")\nso = so.drop_duplicates()\n\nprint(\"Top most highly positive correlated features:\")\nprint(so[(so<1) & (so>0.5)].sort_values(ascending=False))\n\nprint()\n\nprint(\"Top most highly megative correlated features:\")\nprint(so[(so < - 0.005)])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### EDA Summary\n\n- We have 200 features that are mostly uncorrelated between them\n- 200 numerical features that their histograms have a shape like the one of a normal distribution"},{"metadata":{},"cell_type":"markdown","source":"## Machine Learning Modeling"},{"metadata":{},"cell_type":"markdown","source":"![](https://cmci.colorado.edu/classes/INFO-4604/fa17/wordcloud.png)\n[image-source](https://cmci.colorado.edu/classes/INFO-4604/fa17/wordcloud.png)"},{"metadata":{},"cell_type":"markdown","source":"### Feature Engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect();\nfor df in [test, train]:\n    df['sum'] = df[numerical_features].sum(axis=1)  \n    df['min'] = df[numerical_features].min(axis=1)\n    df['max'] = df[numerical_features].max(axis=1)\n    df['mean'] = df[numerical_features].mean(axis=1)\n    df['std'] = df[numerical_features].std(axis=1)\n    df['skew'] = df[numerical_features].skew(axis=1)\n    df['kurt'] = df[numerical_features].kurtosis(axis=1)\n    df['med'] = df[numerical_features].median(axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = train['target']\nX = train.drop(['target', \"ID_code\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def xgboost_all_purpose(X, y, type_of_training):\n    \n    from sklearn.model_selection import train_test_split, StratifiedKFold\n    from sklearn.metrics import accuracy_score\n    from sklearn.metrics import precision_score\n    from sklearn.metrics import recall_score\n    from sklearn.metrics import f1_score\n    from sklearn.metrics import classification_report\n    from sklearn.metrics import roc_auc_score\n    import scikitplot as skplt\n    import time\n    import random\n    \n    import xgboost as xgb\n    \n    # xgboost parameters\n    eta = 0.03\n    estimators  = 8000\n    depth = 6\n    gamma_value = 0\n    colsample_bytree_value = 1\n    max_rounds = 400\n    child_weight = 1\n    \n    if type_of_training == \"baseline\":\n    # create a 70/30 split of the data \n        xtrain, xvalid, ytrain, yvalid = train_test_split(X, y, random_state=42, test_size=0.3)\n    \n        import xgboost as xgb\n\n        start_time = time.time()\n\n        clf_xgb = xgb.XGBClassifier(learning_rate=eta, \n                                    n_estimators=estimators, \n                                    max_depth=depth,\n                                    min_child_weight=child_weight,\n                                    gamma=gamma_value,\n                                    subsample=1,\n                                    colsample_bytree=colsample_bytree_value,\n                                    objective= 'binary:logistic',\n                                    nthread=-1,\n                                    scale_pos_weight=1,\n                                    reg_alpha = 0,\n                                    reg_lambda = 1,\n                                    seed=42)\n\n        clf_xgb.fit(xtrain, ytrain, eval_set=[(xtrain, ytrain), (xvalid, yvalid)], \n                    early_stopping_rounds=max_rounds, eval_metric='auc', verbose=100)\n\n        predictions = clf_xgb.predict(xvalid)\n        predictions_probas = clf_xgb.predict_proba(xvalid)\n\n        print()\n        print(classification_report(yvalid, predictions))\n\n        print()\n        print(\"f1_score\", f1_score(yvalid, predictions, average = \"macro\"))\n\n        print()\n        print(\"elapsed time in seconds: \", time.time() - start_time)\n        \n        sns.set(rc={'figure.figsize':(8, 8)})\n        skplt.metrics.plot_confusion_matrix(yvalid, predictions, normalize=True)\n        \n        predictions_probas = clf_xgb.predict_proba(xvalid)\n        skplt.metrics.plot_roc(yvalid, predictions_probas)\n        \n        skplt.metrics.plot_precision_recall(yvalid, predictions_probas)\n        \n        sns.set(rc={'figure.figsize':(12, 38)})\n        xgb.plot_importance(clf_xgb, title='Feature importance', xlabel='F score', ylabel='Features')\n\n        print()\n        gc.collect();\n        return clf_xgb\n        \n    elif type_of_training == \"stratified\":\n        \n        xtrain, xvalid, ytrain, yvalid = train_test_split(X, y, random_state=42, test_size=0.3)\n        \n        predictions_probas_list = []\n        index_fold = 0\n        best_score = 1\n        \n        folds = StratifiedKFold(n_splits=3, shuffle=True, random_state = 42)\n        \n        clf_stra_xgb = xgb.XGBClassifier(learning_rate=eta, \n                                    n_estimators=estimators, \n                                    max_depth=depth,\n                                    min_child_weight=child_weight,\n                                    gamma=gamma_value,\n                                    subsample=1,\n                                    colsample_bytree=colsample_bytree_value,\n                                    objective= 'binary:logistic',\n                                    nthread=-1,\n                                    scale_pos_weight=1,\n                                    reg_alpha = 0,\n                                    reg_lambda = 1,\n                                    seed=42)\n        \n        for train_index, valid_index in folds.split(xtrain, ytrain):\n            xtrain_stra, xvalid_stra = xtrain.iloc[train_index,:], xtrain.iloc[valid_index,:]\n            ytrain_stra, yvalid_stra = ytrain.iloc[train_index], ytrain.iloc[valid_index]\n\n            print(\"Stratified Fold:\", index_fold)\n            index_fold = index_fold + 1\n            \n            import xgboost as xgb\n\n            start_time = time.time()\n\n\n            clf_stra_xgb.fit(xtrain_stra, ytrain_stra, eval_set=[(xtrain_stra, ytrain_stra), (xvalid_stra, yvalid_stra)], \n                        early_stopping_rounds=max_rounds, eval_metric='auc', verbose=100)\n            \n            #if (clf_stra_xgb.best_score < best_score):\n            #    clf_best_stra_xgb = clf_stra_xgb\n            #    best_score = clf_stra_xgb.best_score\n            \n            print()\n\n            predictions_probas = clf_stra_xgb.predict_proba(xvalid)\n            predictions_probas_list.append(predictions_probas)\n            \n        \n        predictions_probas=[sum(i)/index_fold for i in zip(*predictions_probas_list)]\n        predictions = np.argmax(predictions_probas, axis=1)\n        \n        #xtrain, xvalid, ytrain, yvalid = train_test_split(X, y, random_state=42, test_size=0.3)\n        #clf_stra_xgb = clf_best_stra_xgb\n        #del clf_best_stra_xgb\n        #print(\"Best score:\", best_score)\n        \n        predictions = clf_stra_xgb.predict(xvalid)\n        predictions_probas = clf_stra_xgb.predict_proba(xvalid)\n\n        print()\n        print(classification_report(yvalid, predictions))\n\n        print()\n        print(\"f1_score\", f1_score(yvalid, predictions, average = \"macro\"))\n\n        print()\n        print(\"elapsed time in seconds: \", time.time() - start_time)\n        \n        sns.set(rc={'figure.figsize':(8, 8)})\n        skplt.metrics.plot_confusion_matrix(yvalid, predictions, normalize=True)\n        \n        skplt.metrics.plot_roc(yvalid, predictions_probas)\n        \n        skplt.metrics.plot_precision_recall(yvalid, predictions_probas)\n        \n        sns.set(rc={'figure.figsize':(12, 38)})\n        xgb.plot_importance(clf_stra_xgb, title='Feature importance', xlabel='F score', ylabel='Features')\n\n        print()\n        gc.collect();\n        return clf_stra_xgb\n\n    elif type_of_training == \"oversampling\":\n        \n        #### resampling techniques:\n        from imblearn.over_sampling import SMOTE, ADASYN, RandomOverSampler\n\n        # create a 70/30 split of the data \n        xtrain, xvalid, ytrain, yvalid = train_test_split(X, y, random_state=42, test_size=0.3)\n\n        # RandomOverSampler\n        ros = RandomOverSampler(random_state=42)\n        X_resampled, y_resampled = ros.fit_resample(xtrain, ytrain)\n        xtrain=pd.DataFrame(X_resampled, columns = X.columns)\n        ytrain = y_resampled\n        \n\n        start_time = time.time()\n\n        clf_ros_xgb = xgb.XGBClassifier(learning_rate=eta, \n                                    n_estimators=estimators, \n                                    max_depth=depth,\n                                    min_child_weight=child_weight,\n                                    gamma=gamma_value,\n                                    subsample=1,\n                                    colsample_bytree=colsample_bytree_value,\n                                    objective= 'binary:logistic',\n                                    nthread=-1,\n                                    scale_pos_weight=1,\n                                    reg_alpha = 0,\n                                    reg_lambda = 1,\n                                    seed=42)\n\n        clf_ros_xgb.fit(xtrain, ytrain, eval_set=[(xtrain, ytrain), (xvalid, yvalid)], \n                    early_stopping_rounds=max_rounds, eval_metric='auc', verbose=100)\n\n        predictions = clf_ros_xgb.predict(xvalid)\n        predictions_probas = clf_ros_xgb.predict_proba(xvalid)\n\n        print()\n        print(classification_report(yvalid, predictions))\n\n        print()\n        print(\"f1_score\", f1_score(yvalid, predictions, average = \"macro\"))\n\n        print()\n        print(\"elapsed time in seconds: \", time.time() - start_time)\n        \n        sns.set(rc={'figure.figsize':(8, 8)})\n        skplt.metrics.plot_confusion_matrix(yvalid, predictions, normalize=True)\n        \n        skplt.metrics.plot_roc(yvalid, predictions_probas)\n        \n        skplt.metrics.plot_precision_recall(yvalid, predictions_probas)\n        \n        sns.set(rc={'figure.figsize':(12, 38)})\n        xgb.plot_importance(clf_ros_xgb, title='Feature importance', xlabel='F score', ylabel='Features')\n\n        print()\n        gc.collect();\n        return clf_ros_xgb\n    \n    elif type_of_training == \"smote\":\n        #### resampling techniques:\n        from imblearn.over_sampling import SMOTE, ADASYN, RandomOverSampler\n\n        # create a 70/30 split of the data \n        xtrain, xvalid, ytrain, yvalid = train_test_split(X, y, random_state=42, test_size=0.3)\n\n        # SMOTE\n        smote = SMOTE(random_state=42)\n        X_resampled, y_resampled = smote.fit_resample(xtrain, ytrain)\n        xtrain=pd.DataFrame(X_resampled, columns = X.columns)\n        ytrain = y_resampled\n\n        start_time = time.time()\n\n        clf_smote_xgb = xgb.XGBClassifier(learning_rate=eta, \n                                    n_estimators=estimators, \n                                    max_depth=depth,\n                                    min_child_weight=child_weight,\n                                    gamma=gamma_value,\n                                    subsample=1,\n                                    colsample_bytree=colsample_bytree_value,\n                                    objective= 'binary:logistic',\n                                    nthread=-1,\n                                    scale_pos_weight=1,\n                                    reg_alpha = 0,\n                                    reg_lambda = 1,\n                                    seed=42)\n\n        clf_smote_xgb.fit(xtrain, ytrain, eval_set=[(xtrain, ytrain), (xvalid, yvalid)], \n                    early_stopping_rounds=max_rounds, eval_metric='auc', verbose=100)\n\n        predictions = clf_smote_xgb.predict(xvalid)\n        predictions_probas = clf_smote_xgb.predict_proba(xvalid)\n\n        print()\n        print(classification_report(yvalid, predictions))\n\n        print()\n        print(\"f1_score\", f1_score(yvalid, predictions, average = \"macro\"))\n\n        print()\n        print(\"elapsed time in seconds: \", time.time() - start_time)\n        \n        sns.set(rc={'figure.figsize':(8,8)})\n        skplt.metrics.plot_confusion_matrix(yvalid, predictions, normalize=True)\n        \n        sns.set(rc={'figure.figsize':(8,8)})\n        skplt.metrics.plot_roc(yvalid, predictions_probas)\n        \n        sns.set(rc={'figure.figsize':(8,8)})\n        skplt.metrics.plot_ks_statistic(yvalid, predictions_probas)\n        \n        sns.set(rc={'figure.figsize':(8,8)})\n        skplt.metrics.plot_precision_recall(yvalid, predictions_probas)\n        \n        sns.set(rc={'figure.figsize':(8,8)})\n        skplt.metrics.plot_cumulative_gain(yvalid, predictions_probas)\n\n        sns.set(rc={'figure.figsize':(8,8)})\n        skplt.metrics.plot_lift_curve(yvalid, predictions_probas)\n        \n        sns.set(rc={'figure.figsize':(12, 38)})\n        xgb.plot_importance(clf_smote_xgb, title='Feature importance', xlabel='F score', ylabel='Features')\n\n        print()\n        gc.collect();\n        return clf_smote_xgb\n    \n    elif type_of_training == \"undersampling\":\n        \n        #### resampling techniques:\n        from imblearn.under_sampling import RandomUnderSampler\n\n        # create a 70/30 split of the data \n        xtrain, xvalid, ytrain, yvalid = train_test_split(X, y, random_state=42, test_size=0.3)\n\n        # RandomUnderSampler\n        rus = RandomUnderSampler(random_state=42)\n        X_resampled, y_resampled = rus.fit_resample(xtrain, ytrain)\n        xtrain=pd.DataFrame(X_resampled, columns = X.columns)\n        ytrain = y_resampled\n\n        start_time = time.time()\n\n        clf_rus_xgb = xgb.XGBClassifier(learning_rate=eta, \n                                    n_estimators=estimators, \n                                    max_depth=depth,\n                                    min_child_weight=child_weight,\n                                    gamma=gamma_value,\n                                    subsample=1,\n                                    colsample_bytree=colsample_bytree_value,\n                                    objective= 'binary:logistic',\n                                    nthread=-1,\n                                    scale_pos_weight=1,\n                                    reg_alpha = 0,\n                                    reg_lambda = 1,\n                                    seed=42)\n\n        clf_rus_xgb.fit(xtrain, ytrain, eval_set=[(xtrain, ytrain), (xvalid, yvalid)], \n                    early_stopping_rounds=max_rounds, eval_metric='auc', verbose=100)\n\n        predictions = clf_rus_xgb.predict(xvalid)\n        predictions_probas = clf_rus_xgb.predict_proba(xvalid)\n\n        print()\n        print(classification_report(yvalid, predictions))\n\n        print()\n        print(\"f1_score\", f1_score(yvalid, predictions, average = \"macro\"))\n\n        print()\n        print(\"elapsed time in seconds: \", time.time() - start_time)\n        \n        sns.set(rc={'figure.figsize':(8,8)})\n        skplt.metrics.plot_confusion_matrix(yvalid, predictions, normalize=True)\n        \n        sns.set(rc={'figure.figsize':(8,8)})\n        skplt.metrics.plot_roc(yvalid, predictions_probas)\n        \n        sns.set(rc={'figure.figsize':(8,8)})\n        skplt.metrics.plot_ks_statistic(yvalid, predictions_probas)\n        \n        sns.set(rc={'figure.figsize':(8,8)})\n        skplt.metrics.plot_precision_recall(yvalid, predictions_probas)\n        \n        sns.set(rc={'figure.figsize':(8,8)})\n        skplt.metrics.plot_cumulative_gain(yvalid, predictions_probas)\n\n        sns.set(rc={'figure.figsize':(8,8)})\n        skplt.metrics.plot_lift_curve(yvalid, predictions_probas)\n        \n        sns.set(rc={'figure.figsize':(12, 38)})\n        xgb.plot_importance(clf_rus_xgb, title='Feature importance', xlabel='F score', ylabel='Features')\n\n        print()\n        gc.collect();\n        #return clf_rus_xgb, predictions, predictions_probas\n        return clf_rus_xgb\n    \n    else:\n        print(\"Please specify for the argument 'type_of_training'one of the following parameters: (baseline, stratified, oversampling, smote, undersampling, tomek)\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_xgb = xgboost_all_purpose(X,y, type_of_training =\"baseline\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rus_clf_xgb = xgboost_all_purpose(X,y, type_of_training =\"undersampling\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"### code for testing\n'''\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import roc_auc_score\nimport time\n\n# create a 70/30 split of the data \nxtrain, xvalid, ytrain, yvalid = train_test_split(X, y, stratify = y, random_state=42, test_size=0.3)\n\nimport xgboost as xgb\n\nstart_time = time.time()\n\nclf_xgb = xgb.XGBClassifier(learning_rate=0.05, \n                            n_estimators=3000, \n                            max_depth=6,\n                            min_child_weight=1,\n                            gamma=0,\n                            subsample=1,\n                            colsample_bytree=1,\n                            objective= 'binary:logistic',\n                            nthread=-1,\n                            scale_pos_weight=1,\n                            reg_alpha = 0,\n                            reg_lambda = 1,\n                            seed=42)\n\nclf_xgb.fit(xtrain, ytrain, eval_set=[(xtrain, ytrain), (xvalid, yvalid)], \n            early_stopping_rounds=100, eval_metric='auc', verbose=100)\n\npredictions = clf_xgb.predict(xvalid)\n\nprint()\nprint(classification_report(yvalid, predictions))\n\nprint()\nprint(\"accuracy_score\", accuracy_score(yvalid, predictions))\n\nprint()\npredictions_probas = clf_xgb.predict_proba(xvalid)\nprint(\"roc-auc score\", roc_auc_score(yvalid, predictions_probas[:,1]))\n\nprint()\nprint(\"elapsed time in seconds: \", time.time() - start_time)\n\nprint()\ngc.collect()\n'''","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature Selection - Permutation Importance"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\n\ntrain_X, val_X, train_y, val_y = train_test_split(X, y, random_state=42)\nrfc_model = RandomForestClassifier(random_state=42).fit(train_X, train_y)\n\nimport eli5\nfrom eli5.sklearn import PermutationImportance\n\nperm = PermutationImportance(rfc_model, random_state=42).fit(val_X, val_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eli5.show_weights(perm, feature_names = val_X.columns.tolist(), top=100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Select top 100 features after permutation importance:"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import SelectFromModel\n\nmax_selected_features = 100\nsel = SelectFromModel(perm, max_features = max_selected_features, prefit=True)\nX_trans = sel.transform(X)\n\nfeature_idx = sel.get_support()\nfeature_name = X.columns[feature_idx]\n\nX_trans = X[feature_name]\nX_trans.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### XGBoost Training after Feature Selection"},{"metadata":{"trusted":true},"cell_type":"code","source":"trans_clf_xgb = xgboost_all_purpose(X_trans,y, type_of_training =\"baseline\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rus_trans_clf_xgb = xgboost_all_purpose(X_trans,y, type_of_training =\"undersampling\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## ML Blends\n** To be updated **"},{"metadata":{},"cell_type":"markdown","source":"## Preparing for submmission"},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect();\nsubmission = pd.read_csv('../input/sample_submission.csv')\nsubmission['target'] = clf_xgb.predict(test.drop(\"ID_code\", axis=\"columns\"))\nsubmission.to_csv('xgboost.csv', index=False)\n\ngc.collect();\nsubmission = pd.read_csv('../input/sample_submission.csv')\nsubmission['target'] = clf_rus_xgb.predict(test.drop(\"ID_code\", axis=\"columns\"))\nsubmission.to_csv('xgboost_rus.csv', index=False)\n\n\ngc.collect();\nsubmission = pd.read_csv('../input/sample_submission.csv')\nsubmission['target'] = trans_clf_xgb.predict(test.drop(\"ID_code\", axis=\"columns\"))\nsubmission.to_csv('xgboost_trans.csv', index=False)\n\ngc.collect();\nsubmission = pd.read_csv('../input/sample_submission.csv')\nsubmission['target'] = rus_trans_clf_xgb.predict(test.drop(\"ID_code\", axis=\"columns\"))\nsubmission.to_csv('xgboost_trans_xgb.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Conclusion\nWe can see from EDA and ML Modeling that class #1 is very unbalanced and difficult to identified and classified."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}